{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "You just got hired as the first and only data practitioner at a small business experiencing exponential growth. The company needs more structured processes, guidelines, and standards. Your first mission is to structure the human resources data. The data is currently scattered across teams and files and comes in various formats: Excel files, CSVs, JSON files...\n",
    "\n",
    "You'll work with the following data in the `datasets` folder:\n",
    "- __Office addresses__\n",
    "    - Saved in `office_addresses.csv`. \n",
    "    - If the value for office is `NaN`, then the employee is remote.\n",
    "- __Employee addresses__\n",
    "    - Saved on the first tab of `employee_information.xlsx`.\n",
    "- __Employee emergency contacts__ \n",
    "    - Saved on the second tab of `employee_information.xlsx`; this tab is called `emergency_contacts`. \n",
    "    - However, this sheet was edited at some point, and ***the headers were removed***! The HR manager let you know that they should be: `employee_id`, `last_name`, `first_name`, `emergency_contact`, `emergency_contact_number`, and `relationship`.\n",
    "- __Employee roles, teams, and salaries__ \n",
    "    - This information has been exported from the company's human resources management system into a JSON file titled `employee_roles.json`. Here are the first few lines of that file:\n",
    "```\n",
    "\n",
    "{\"A2R5H9\":\n",
    "  {\n",
    "    \"title\": \"CEO\",\n",
    "    \"monthly_salary\": \"$4500\",\n",
    "    \"team\": \"Leadership\"\n",
    "  },\n",
    " ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary packages\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the files\n",
    "employee_addresses = pd.read_excel(\"employee_information.xlsx\", sheet_name = 0)\n",
    "\n",
    "employee_roles = pd.read_json(\"employee_roles.json\").T\n",
    "employee_roles.reset_index(drop=False, inplace=True)\n",
    "\n",
    "office_address = pd.read_csv(\"office_addresses.csv\")\n",
    "\n",
    "\n",
    "#All these is me trying to insert a header row that will label the unlabeled columns\n",
    "# Specify the new column names\n",
    "new_column_names = [\n",
    "    'employee_id',\n",
    "    'employee_last_name',\n",
    "    'employee_first_name',\n",
    "    'emergency_contact',\n",
    "    'emergency_contact_number',\n",
    "    'relationship'\n",
    "]\n",
    "\n",
    "# Read the Excel file without header\n",
    "emergency_contacts = pd.read_excel(\"employee_information.xlsx\", sheet_name=1, header=None, names = new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "employees_final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am adding the first 7 columns into the new data frame\n",
    "employees_final = pd.concat([employees_final, employee_addresses], ignore_index = True)\n",
    "\n",
    "#Swapping the first name with the last name\n",
    "employees_final = employees_final.iloc[:, [0,2,1] + list(range(3, len(employees_final.columns)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the next 3 columns to the final file.\n",
    "next_3 = emergency_contacts.iloc[:, 3:6]\n",
    "\n",
    "employees_final = pd.concat([employees_final, next_3], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now adding the next 3 columns from the json file\n",
    "cols_11_13 = employee_roles[['monthly_salary', 'team', 'title']]\n",
    "\n",
    "employees_final = pd.concat([employees_final, cols_11_13], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge employees with offices based on employee_country and office_country\n",
    "employees_final = pd.merge(employees_final, office_address, how='left', left_on='employee_country', right_on='office_country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15312\\3446274966.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Remote' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  employees_final.fillna(\"Remote\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "employees_final.fillna(\"Remote\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the employee_id as the index\n",
    "employees_final = employees_final.set_index(employees_final.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_first_name</th>\n",
       "      <th>employee_last_name</th>\n",
       "      <th>employee_country</th>\n",
       "      <th>employee_city</th>\n",
       "      <th>employee_street</th>\n",
       "      <th>employee_street_number</th>\n",
       "      <th>emergency_contact</th>\n",
       "      <th>emergency_contact_number</th>\n",
       "      <th>relationship</th>\n",
       "      <th>monthly_salary</th>\n",
       "      <th>team</th>\n",
       "      <th>title</th>\n",
       "      <th>office</th>\n",
       "      <th>office_country</th>\n",
       "      <th>office_city</th>\n",
       "      <th>office_street</th>\n",
       "      <th>office_street_number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A2R5H9</th>\n",
       "      <td>Jax</td>\n",
       "      <td>Hunman</td>\n",
       "      <td>BE</td>\n",
       "      <td>Leuven</td>\n",
       "      <td>Grote Markt</td>\n",
       "      <td>9</td>\n",
       "      <td>Opie Hurst</td>\n",
       "      <td>+32-456-5556-84</td>\n",
       "      <td>Brother</td>\n",
       "      <td>$4500</td>\n",
       "      <td>Leadership</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Leuven Office</td>\n",
       "      <td>BE</td>\n",
       "      <td>Leuven</td>\n",
       "      <td>Martelarenlaan</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H8K0L6</th>\n",
       "      <td>Tara</td>\n",
       "      <td>Siff</td>\n",
       "      <td>GB</td>\n",
       "      <td>London</td>\n",
       "      <td>Baker Street</td>\n",
       "      <td>221</td>\n",
       "      <td>Wendy de Matteo</td>\n",
       "      <td>+44-020-5554-333</td>\n",
       "      <td>Sister</td>\n",
       "      <td>$4500</td>\n",
       "      <td>Leadership</td>\n",
       "      <td>CFO</td>\n",
       "      <td>WeWork Office</td>\n",
       "      <td>GB</td>\n",
       "      <td>London</td>\n",
       "      <td>Old Street</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G4R7V0</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>Sagal</td>\n",
       "      <td>US</td>\n",
       "      <td>New-York</td>\n",
       "      <td>Perry Street</td>\n",
       "      <td>66</td>\n",
       "      <td>John Newmark</td>\n",
       "      <td>+1-202-555-194</td>\n",
       "      <td>Husband</td>\n",
       "      <td>$3000</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Business Developer</td>\n",
       "      <td>ESB Office</td>\n",
       "      <td>US</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Fifth Avenue</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1Z7U9</th>\n",
       "      <td>Tig</td>\n",
       "      <td>Coates</td>\n",
       "      <td>FR</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rue de l'Universit√©</td>\n",
       "      <td>7</td>\n",
       "      <td>Venus Noone</td>\n",
       "      <td>+1-202-555-0130</td>\n",
       "      <td>Wife</td>\n",
       "      <td>$2000</td>\n",
       "      <td>People Operations</td>\n",
       "      <td>Office Manager</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            employee_first_name employee_last_name employee_country  \\\n",
       "employee_id                                                           \n",
       "A2R5H9                      Jax             Hunman               BE   \n",
       "H8K0L6                     Tara               Siff               GB   \n",
       "G4R7V0                    Gemma              Sagal               US   \n",
       "M1Z7U9                      Tig             Coates               FR   \n",
       "\n",
       "            employee_city      employee_street  employee_street_number  \\\n",
       "employee_id                                                              \n",
       "A2R5H9             Leuven          Grote Markt                       9   \n",
       "H8K0L6             London         Baker Street                     221   \n",
       "G4R7V0           New-York         Perry Street                      66   \n",
       "M1Z7U9              Paris  Rue de l'Universit√©                       7   \n",
       "\n",
       "            emergency_contact emergency_contact_number relationship  \\\n",
       "employee_id                                                           \n",
       "A2R5H9             Opie Hurst          +32-456-5556-84      Brother   \n",
       "H8K0L6        Wendy de Matteo         +44-020-5554-333       Sister   \n",
       "G4R7V0           John Newmark           +1-202-555-194      Husband   \n",
       "M1Z7U9            Venus Noone          +1-202-555-0130         Wife   \n",
       "\n",
       "            monthly_salary               team               title  \\\n",
       "employee_id                                                         \n",
       "A2R5H9               $4500         Leadership                 CEO   \n",
       "H8K0L6               $4500         Leadership                 CFO   \n",
       "G4R7V0               $3000              Sales  Business Developer   \n",
       "M1Z7U9               $2000  People Operations      Office Manager   \n",
       "\n",
       "                    office office_country    office_city   office_street  \\\n",
       "employee_id                                                                \n",
       "A2R5H9       Leuven Office             BE         Leuven  Martelarenlaan   \n",
       "H8K0L6       WeWork Office             GB         London      Old Street   \n",
       "G4R7V0          ESB Office             US  New York City    Fifth Avenue   \n",
       "M1Z7U9              Remote         Remote         Remote          Remote   \n",
       "\n",
       "            office_street_number  \n",
       "employee_id                       \n",
       "A2R5H9                      38.0  \n",
       "H8K0L6                     207.0  \n",
       "G4R7V0                     350.0  \n",
       "M1Z7U9                    Remote  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``CHAPTER 2: ADVANCED ETL TECHNIQUES.``\n",
    "\n",
    "**A). Advanced data transformation with pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing values with pandas:\n",
    "\n",
    "When building data pipelines, it's inevitable that you'll stumble upon missing data. In some cases, you may want to remove these records from the dataset. But in others, you'll need to impute values for the missing information. In this exercise, you'll practice using pandas to impute missing test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping data with pandas\n",
    "\n",
    "The output of a data pipeline is typically a \"modeled\" dataset. This dataset provides data consumers easy access to information, without having to perform much manipulation. Grouping data with pandas helps to build modeled datasets,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying advanced transformations to DataFrames\n",
    "\n",
    "pandas has a plethora of built-in transformation tools, but sometimes, more advanced logic needs to be used in a transformation. The apply function lets you apply a user-defined function to a row or column of a DataFrame, opening the door for advanced transformation and feature generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![trainers in a store](trainers.jpg)\n",
    "\n",
    "Sports clothing and athleisure attire is a huge industry, worth approximately [$193 billion in 2021](https://www.statista.com/statistics/254489/total-revenue-of-the-global-sports-apparel-market/) with a strong growth forecast over the next decade! \n",
    "\n",
    "In this notebook, you will undertake the role of a product analyst for an online sports clothing company. The company is specifically interested in how it can improve revenue. You will dive into product data such as pricing, reviews, descriptions, and ratings, as well as revenue and website traffic, to produce recommendations for its marketing and sales teams.  \n",
    "\n",
    "You've been provided with four datasets to investigate:\n",
    "\n",
    "#  brands.csv\n",
    "\n",
    "| Columns | Description |\n",
    "|---------|-------------|\n",
    "| `product_id` | Unique product identifier |\n",
    "| `brand` | Brand of the product | \n",
    "\n",
    "# finance.csv\n",
    "\n",
    "| Columns | Description |\n",
    "|---------|-------------|\n",
    "| `product_id` | Unique product identifier |\n",
    "| `listing_price` | Original price of the product | \n",
    "| `sale_price` | Discounted price of the product |\n",
    "| `discount` | Discount off the listing price, as a decimal | \n",
    "| `revenue` | Revenue generated by the product |\n",
    "\n",
    "# info.csv\n",
    "\n",
    "| Columns | Description |\n",
    "|---------|-------------|\n",
    "| `product_name` | Name of the product | \n",
    "| `product_id` | Unique product identifier |\n",
    "| `description` | Description of the product |\n",
    "\n",
    "# reviews.csv\n",
    "\n",
    "| Columns | Description |\n",
    "|---------|-------------|\n",
    "| `product_id` | Unique product identifier |\n",
    "| `rating` | Average product rating | \n",
    "| `reviews` | Number of reviews for the product |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = pd.read_csv(\"brands.csv\")\n",
    "finance = pd.read_csv(\"finance.csv\")\n",
    "info = pd.read_csv(\"info.csv\")\n",
    "reviews = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete the project you will need to merge the datasets and drop null values, along with answering the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>listing_price</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>discount</th>\n",
       "      <th>revenue</th>\n",
       "      <th>product_name</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130690-017</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6909.84</td>\n",
       "      <td>Air Jordan 12 Retro</td>\n",
       "      <td>An all-time favourite among players and sneake...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133000-106</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0.00</td>\n",
       "      <td>119.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Air Jordan OG</td>\n",
       "      <td>First released in '98, the Air Jordan OG was d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280648</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>29.99</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2915.03</td>\n",
       "      <td>Men's Originals Summer Adilette Slippers</td>\n",
       "      <td>From 72' until now, these adidas Originals San...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288022</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>29.99</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5128.29</td>\n",
       "      <td>Men's Originals Summer Adilette Slides</td>\n",
       "      <td>The adidas Originals Adilette slip ons for men...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310805-137</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64203.93</td>\n",
       "      <td>Air Jordan 10 Retro</td>\n",
       "      <td>Featuring soft, lightweight cushioning, the Ai...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id   brand  listing_price  sale_price  discount   revenue  \\\n",
       "0  130690-017    Nike           0.00      159.95       0.0   6909.84   \n",
       "1  133000-106    Nike           0.00      119.95       0.0      0.00   \n",
       "2      280648  Adidas          29.99       29.99       0.0   2915.03   \n",
       "3      288022  Adidas          29.99       29.99       0.0   5128.29   \n",
       "4  310805-137    Nike           0.00      159.95       0.0  64203.93   \n",
       "\n",
       "                               product_name  \\\n",
       "0                       Air Jordan 12 Retro   \n",
       "1                             Air Jordan OG   \n",
       "2  Men's Originals Summer Adilette Slippers   \n",
       "3    Men's Originals Summer Adilette Slides   \n",
       "4                       Air Jordan 10 Retro   \n",
       "\n",
       "                                         description  rating  reviews  \n",
       "0  An all-time favourite among players and sneake...     4.5     24.0  \n",
       "1  First released in '98, the Air Jordan OG was d...     0.0      0.0  \n",
       "2  From 72' until now, these adidas Originals San...     4.2     54.0  \n",
       "3  The adidas Originals Adilette slip ons for men...     3.3     95.0  \n",
       "4  Featuring soft, lightweight cushioning, the Ai...     4.7    223.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the data sets\n",
    "df = pd.merge(brands, finance, on='product_id', how='outer')\n",
    "df = pd.merge(df, info, on='product_id', how='outer')\n",
    "df = pd.merge(df, reviews, on='product_id', how='outer')\n",
    "\n",
    "# Set 'product_id' as the first column\n",
    "df = df[['product_id'] + [col for col in df.columns if col != 'product_id']]\n",
    "\n",
    "#Drop the null value\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the volume of products and average revenue for Adidas and Nike products based on listing price quartiles?\n",
    "\n",
    "Label products priced up to quartile one as \"Budget\", quartile two as \"Average\", quartile three as \"Expensive\", and quartile four as \"Elite\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15312\\1519729351.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  adidas_volume_revenue = adidas.groupby('listing_price_label').agg(volume=('listing_price_label', 'count'), mean_revenue=('revenue', 'mean'))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15312\\1519729351.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  nike_volume_revenue = nike.groupby('listing_price_label').agg(volume=('listing_price_label', 'count'), mean_revenue=('revenue', 'mean'))\n"
     ]
    }
   ],
   "source": [
    "# Calculate listing price quartiles for all products\n",
    "quartiles = pd.qcut(df['listing_price'], q=4, labels=['Budget', 'Average', 'Expensive', 'Elite'])\n",
    "\n",
    "# Add quartiles as a new column to the DataFrame\n",
    "df['listing_price_label'] = quartiles\n",
    "\n",
    "# Filter the DataFrame to separate Adidas and Nike products\n",
    "adidas = df[df['brand'] == 'Adidas']\n",
    "nike = df[df['brand'] == 'Nike']\n",
    "\n",
    "# Calculate volume and average revenue for Adidas products based on quartiles\n",
    "adidas_volume_revenue = adidas.groupby('listing_price_label').agg(volume=('listing_price_label', 'count'), mean_revenue=('revenue', 'mean'))\n",
    "\n",
    "# Calculate volume and average revenue for Nike products based on quartiles\n",
    "nike_volume_revenue = nike.groupby('listing_price_label').agg(volume=('listing_price_label', 'count'), mean_revenue=('revenue', 'mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store as a pandas DataFrame called adidas_vs_nike containing the following columns: \"brand\", \"price_label\", \"num_products\", and \"mean_revenue\". All numeric values should be rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>price_label</th>\n",
       "      <th>num_products</th>\n",
       "      <th>mean_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>Budget</td>\n",
       "      <td>574</td>\n",
       "      <td>2015.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>Average</td>\n",
       "      <td>655</td>\n",
       "      <td>3035.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>Expensive</td>\n",
       "      <td>759</td>\n",
       "      <td>4621.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>Elite</td>\n",
       "      <td>587</td>\n",
       "      <td>8302.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Budget</td>\n",
       "      <td>357</td>\n",
       "      <td>1596.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand price_label  num_products  mean_revenue\n",
       "0  Adidas      Budget           574       2015.68\n",
       "1  Adidas     Average           655       3035.30\n",
       "2  Adidas   Expensive           759       4621.56\n",
       "3  Adidas       Elite           587       8302.78\n",
       "4    Nike      Budget           357       1596.33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adidas_vs_nike = pd.DataFrame(columns = [\"brand\", \"price_label\", \"num_products\",\"mean_revenue\"])\n",
    "\n",
    "# Concatenate Adidas and Nike results\n",
    "adidas_vs_nike = pd.concat([adidas_volume_revenue, nike_volume_revenue], keys=['Adidas', 'Nike']).reset_index()\n",
    "adidas_vs_nike.rename(columns={'level_0': 'brand'}, inplace=True)\n",
    "adidas_vs_nike['mean_revenue'] = adidas_vs_nike['mean_revenue'].round(2)\n",
    "\n",
    "adidas_vs_nike.rename(columns={'volume': 'num_products', 'listing_price_label': 'price_label'}, inplace=True)\n",
    "\n",
    "\n",
    "adidas_vs_nike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do any differences exist between the word count of a product's description and its mean rating?\n",
    "\n",
    "Split product description length into bins of 100 characters and calculate the average rating and number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15312\\2342081473.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  description_lengths = df.groupby('description_length').agg(\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each product's description\n",
    "df['description_length'] = df['description'].str.len()\n",
    "\n",
    "# Split description lengths into bins of 100 characters\n",
    "# bins = range(0, df['description_length'].max() + 101, 100)\n",
    "df['description_length'] = pd.cut(df['description_length'], bins = [0, 100, 200, 300, 400, 500, 600, 700], labels = [\"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\"])\n",
    "\n",
    "# Calculate average rating and number of reviews for each bin\n",
    "description_lengths = df.groupby('description_length').agg(\n",
    "    mean_rating=('rating', 'mean'),\n",
    "    num_reviews=('reviews', 'count')\n",
    ")\n",
    "\n",
    "# Round numeric values to two decimal places\n",
    "description_lengths = description_lengths.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results as a pandas DataFrame called description_lengths containing the following columns: \"description_length\", \"mean_rating\", \"num_reviews\", again rounding numeric values to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the index column\n",
    "description_lengths.index.name = 'description_length'\n",
    "\n",
    "# Reset index to convert the index into a column\n",
    "description_lengths.reset_index(inplace=True)\n",
    "\n",
    "# Create the DataFrame with the specified columns\n",
    "# description_lengths = description_lengths[['description_length', 'mean_rating', 'num_reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_length</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>num_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2.26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>3.19</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>3.29</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>3.35</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>3.12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  description_length  mean_rating  num_reviews\n",
       "0                100         2.26            7\n",
       "1                200         3.19          526\n",
       "2                300         3.28         1785\n",
       "3                400         3.29          651\n",
       "4                500         3.35          118\n",
       "5                600         3.12           15\n",
       "6                700         3.65           15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
